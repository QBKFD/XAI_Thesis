{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   buying_high  buying_low  buying_med  buying_vhigh  maint_high  maint_low  \\\n",
      "0        False       False       False          True       False      False   \n",
      "1        False       False       False          True       False      False   \n",
      "2        False       False       False          True       False      False   \n",
      "3        False       False       False          True       False      False   \n",
      "4        False       False       False          True       False      False   \n",
      "\n",
      "   maint_med  maint_vhigh  doors_2  doors_3  ...  persons_2  persons_4  \\\n",
      "0      False         True     True    False  ...       True      False   \n",
      "1      False         True     True    False  ...       True      False   \n",
      "2      False         True     True    False  ...       True      False   \n",
      "3      False         True     True    False  ...       True      False   \n",
      "4      False         True     True    False  ...       True      False   \n",
      "\n",
      "   persons_more  lug_boot_big  lug_boot_med  lug_boot_small  safety_high  \\\n",
      "0         False         False         False            True        False   \n",
      "1         False         False         False            True        False   \n",
      "2         False         False         False            True         True   \n",
      "3         False         False          True           False        False   \n",
      "4         False         False          True           False        False   \n",
      "\n",
      "   safety_low  safety_med  class  \n",
      "0        True       False      1  \n",
      "1       False        True      1  \n",
      "2       False       False      1  \n",
      "3        True       False      1  \n",
      "4       False        True      1  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "data_cr = pd.read_csv(\"/Users/x/Downloads/car - car.xlsx.csv\", header=None)\n",
    "\n",
    "# Assign column names based on the provided information\n",
    "column_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "data_cr.columns = column_names\n",
    "\n",
    "# Ensure the 'class' column is the last column\n",
    "class_column = data_cr.pop('class')\n",
    "\n",
    "# Map target variable values to integers\n",
    "target_mapping = {'unacc': 1, 'acc': 2, 'good': 3, 'vgood': 4}\n",
    "class_column = class_column.map(target_mapping)\n",
    "\n",
    "# Create dummy variables for all categorical features\n",
    "data_cr = pd.get_dummies(data_cr)\n",
    "\n",
    "# Reattach the 'class' column at the end\n",
    "data_cr['class'] = class_column\n",
    "\n",
    "# Display the first few rows of the modified DataFrame\n",
    "print(data_cr.head())\n",
    "\n",
    "data_cr.to_csv(\"/Users/x/Downloads/processed_car_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   buying_high  buying_low  buying_med  buying_vhigh  maint_high  maint_low  \\\n",
      "0            0           0           0             1           0          0   \n",
      "1            0           0           0             1           0          0   \n",
      "2            0           0           0             1           0          0   \n",
      "3            0           0           0             1           0          0   \n",
      "4            0           0           0             1           0          0   \n",
      "\n",
      "   maint_med  maint_vhigh  doors_2  doors_3  ...  persons_2  persons_4  \\\n",
      "0          0            1        1        0  ...          1          0   \n",
      "1          0            1        1        0  ...          1          0   \n",
      "2          0            1        1        0  ...          1          0   \n",
      "3          0            1        1        0  ...          1          0   \n",
      "4          0            1        1        0  ...          1          0   \n",
      "\n",
      "   persons_more  lug_boot_big  lug_boot_med  lug_boot_small  safety_high  \\\n",
      "0             0             0             0               1            0   \n",
      "1             0             0             0               1            0   \n",
      "2             0             0             0               1            1   \n",
      "3             0             0             1               0            0   \n",
      "4             0             0             1               0            0   \n",
      "\n",
      "   safety_low  safety_med  class  \n",
      "0           1           0      1  \n",
      "1           0           1      1  \n",
      "2           0           0      1  \n",
      "3           1           0      1  \n",
      "4           0           1      1  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "data_cr = pd.read_csv(\"/Users/x/Downloads/car - car.xlsx.csv\", header=None)\n",
    "\n",
    "# Assign column names based on the provided information\n",
    "column_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "data_cr.columns = column_names\n",
    "\n",
    "# Map target variable values to integers\n",
    "target_mapping = {'unacc': 1, 'acc': 2, 'good': 3, 'vgood': 4}\n",
    "data_cr['class'] = data_cr['class'].map(target_mapping)\n",
    "\n",
    "# Create dummy variables for all categorical features\n",
    "data_cr = pd.get_dummies(data_cr, columns=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])\n",
    "\n",
    "# Convert all boolean values to integers\n",
    "data_cr = data_cr.astype(int)\n",
    "\n",
    "# Ensure the 'class' column is the last column\n",
    "class_column = data_cr.pop('class')\n",
    "data_cr['class'] = class_column\n",
    "\n",
    "# Display the first few rows of the modified DataFrame\n",
    "print(data_cr.head())\n",
    "\n",
    "data_cr.to_csv(\"/Users/x/Downloads/ro_cars.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     RI             Na            Mg              Al  \\\n",
      "0       1.517985_to_inf  10.075_to_inf  0.335_to_inf  -inf_to_14.065   \n",
      "1  1.517195_to_1.517985  10.075_to_inf  0.335_to_inf  -inf_to_14.065   \n",
      "2      -inf_to_1.517195  10.075_to_inf  0.335_to_inf  -inf_to_14.065   \n",
      "3  1.517195_to_1.517985  10.075_to_inf  0.335_to_inf  -inf_to_14.065   \n",
      "4  1.517195_to_1.517985  10.075_to_inf  0.335_to_inf  -inf_to_14.065   \n",
      "\n",
      "             Si             K           Ca            Ba                Fe  \\\n",
      "0  0.745_to_inf  -inf_to_1.39  1.39_to_inf  -inf_to_1.39  -inf_to_1.517195   \n",
      "1  0.745_to_inf  -inf_to_1.39  1.39_to_inf  -inf_to_1.39  -inf_to_1.517195   \n",
      "2  0.745_to_inf  -inf_to_1.39  1.39_to_inf  -inf_to_1.39  -inf_to_1.517195   \n",
      "3  0.745_to_inf  -inf_to_1.39  1.39_to_inf  -inf_to_1.39  -inf_to_1.517195   \n",
      "4  0.745_to_inf  -inf_to_1.39  1.39_to_inf  -inf_to_1.39  -inf_to_1.517195   \n",
      "\n",
      "   Type  \n",
      "0     1  \n",
      "1     1  \n",
      "2     1  \n",
      "3     1  \n",
      "4     1  \n"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/x/Downloads/glass - glass.xlsx.csv'\n",
    "data = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# Define bin edges for each feature\n",
    "bins_dict = {\n",
    "    0: [-np.inf, 1.517195, 1.517985, np.inf],  # RI\n",
    "    1: [-np.inf, 8.315, 10.075, np.inf],       # Na\n",
    "    2: [-np.inf, 0.335, np.inf],               # Mg\n",
    "    3: [-np.inf, 14.065, np.inf],              # Al\n",
    "    4: [-np.inf, 0.055, 0.745, np.inf],        # Si\n",
    "    5: [-np.inf, 1.39, np.inf],                # K\n",
    "    6: [-np.inf, 1.39, np.inf],                # Ca\n",
    "    7: [-np.inf, 1.39, np.inf],                # Ba\n",
    "    8: [-np.inf, 1.517195, np.inf]             # Fe\n",
    "}\n",
    "\n",
    "# Function to determine bin labels\n",
    "def create_bin_labels(bins):\n",
    "    bin_labels = []\n",
    "    for i in range(len(bins) - 1):\n",
    "        if bins[i] == -np.inf:\n",
    "            label = f\"{bins[i]}_to_{bins[i + 1]}\"\n",
    "        elif bins[i + 1] == np.inf:\n",
    "            label = f\"{bins[i]}_to_{bins[i + 1]}\"\n",
    "        else:\n",
    "            label = f\"{bins[i]}_to_{bins[i + 1]}\"\n",
    "        bin_labels.append(label)\n",
    "    return bin_labels\n",
    "\n",
    "# Apply binning\n",
    "transformed_data = pd.DataFrame()\n",
    "\n",
    "for column, bins in bins_dict.items():\n",
    "    bin_labels = create_bin_labels(bins)\n",
    "    transformed_data[column] = pd.cut(data[column], bins=bins, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "# Add Type column\n",
    "transformed_data[9] = data[9]\n",
    "\n",
    "# Rename columns for clarity\n",
    "transformed_data.columns = [\n",
    "    'RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type'\n",
    "]\n",
    "\n",
    "print(transformed_data.head())\n",
    "\n",
    "transformed_data.to_csv('/Users/x/Downloads/transformed_glass.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covtype (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/x/Downloads/transformed_covtype_sampled.csv'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/x/Downloads/covertype 2/covtype.data.gz'\n",
    "data = pd.read_csv(file_path, header=None, compression='gzip')\n",
    "\n",
    "# Randomly sample 300,000 rows from the dataset\n",
    "data_sampled = data.sample(n=300000, random_state=42)\n",
    "\n",
    "# Example bin definitions (this should be adjusted based on the actual range of your data)\n",
    "bins_dict = {\n",
    "    0: [-np.inf, 2000, 3000, np.inf],  # Example binning for column 0\n",
    "    1: [-np.inf, 50, 100, np.inf],     # Example binning for column 1\n",
    "    2: [-np.inf, 5, 10, np.inf],       # Example binning for column 2\n",
    "    3: [-np.inf, 100, 200, np.inf],    # Example binning for column 3\n",
    "}\n",
    "\n",
    "# Function to determine bin labels\n",
    "def create_bin_labels(bins):\n",
    "    bin_labels = []\n",
    "    for i in range(len(bins) - 1):\n",
    "        if bins[i] == -np.inf:\n",
    "            label = f\"{bins[i]}_to_{bins[i + 1]}\"\n",
    "        elif bins[i + 1] == np.inf:\n",
    "            label = f\"{bins[i]}_to_{bins[i + 1]}\"\n",
    "        else:\n",
    "            label = f\"{bins[i]}_to_{bins[i + 1]}\"\n",
    "        bin_labels.append(label)\n",
    "    return bin_labels\n",
    "\n",
    "# Apply binning\n",
    "transformed_data = pd.DataFrame()\n",
    "\n",
    "for column, bins in bins_dict.items():\n",
    "    bin_labels = create_bin_labels(bins)\n",
    "    transformed_data[column] = pd.cut(data_sampled[column], bins=bins, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "# Add remaining columns without binning\n",
    "for column in range(len(data_sampled.columns)):\n",
    "    if column not in bins_dict:\n",
    "        transformed_data[column] = data_sampled[column]\n",
    "\n",
    "output_file_path = '/Users/x/Downloads/transformed_covtype_sampled.csv'\n",
    "transformed_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "output_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diabetes (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/x/Downloads/transformed_diabetes.csv'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/x/Downloads/diabetes.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Example bin definitions (this should be adjusted based on the actual range of your data)\n",
    "bins_dict = {\n",
    "    0: [-np.inf, 2000, 3000, np.inf],  # Example binning for column 0\n",
    "    1: [-np.inf, 50, 100, np.inf],     # Example binning for column 1\n",
    "    2: [-np.inf, 5, 10, np.inf],       # Example binning for column 2\n",
    "    3: [-np.inf, 100, 200, np.inf],    # Example binning for column 3\n",
    "}\n",
    "\n",
    "# Function to determine bin labels\n",
    "def create_bin_labels(bins):\n",
    "    bin_labels = []\n",
    "    for i in range(len(bins) - 1):\n",
    "        if bins[i] == -np.inf:\n",
    "            label = f\"{bins[i]}_to_{bins[i + 1]}\"\n",
    "        elif bins[i + 1] == np.inf:\n",
    "            label = f\"{bins[i]}_to_{bins[i + 1]}\"\n",
    "        else:\n",
    "            label = f\"{bins[i]}_to_{bins[i + 1]}\"\n",
    "        bin_labels.append(label)\n",
    "    return bin_labels\n",
    "\n",
    "# Apply binning\n",
    "transformed_data = pd.DataFrame()\n",
    "\n",
    "for column, bins in bins_dict.items():\n",
    "    bin_labels = create_bin_labels(bins)\n",
    "    transformed_data[column] = pd.cut(data.iloc[:, column], bins=bins, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "# Add remaining columns without binning\n",
    "for column in range(len(data.columns)):\n",
    "    if column not in bins_dict:\n",
    "        transformed_data[column] = data.iloc[:, column]\n",
    "\n",
    "output_file_path = '/Users/x/Downloads/transformed_diabetes.csv'\n",
    "transformed_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "output_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doctor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/x/Downloads/transformed_NPHA_doctor_visits.csv'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/x/Downloads/NPHA-doctor-visits.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Example bin definitions (this should be adjusted based on the actual range of your data)\n",
    "bins_dict = {\n",
    "    'Number of Doctors Visited': [-np.inf, 1, 2, np.inf],  # Example binning for column\n",
    "    'Age': [-np.inf, 20, 40, np.inf],                      # Example binning for column\n",
    "    'Phyiscal Health': [-np.inf, 2, 4, np.inf],            # Example binning for column\n",
    "    'Mental Health': [-np.inf, 2, 4, np.inf]               # Example binning for column\n",
    "}\n",
    "\n",
    "# Function to determine bin labels\n",
    "def create_bin_labels(bins):\n",
    "    bin_labels = []\n",
    "    for i in range(len(bins) - 1):\n",
    "        if bins[i] == -np.inf:\n",
    "            label = f\"less_than_{bins[i + 1]}\"\n",
    "        elif bins[i + 1] == np.inf:\n",
    "            label = f\"{bins[i]}_or_more\"\n",
    "        else:\n",
    "            label = f\"{bins[i]}_to_{bins[i + 1]}\"\n",
    "        bin_labels.append(label)\n",
    "    return bin_labels\n",
    "\n",
    "# Apply binning\n",
    "transformed_data = pd.DataFrame()\n",
    "\n",
    "for column, bins in bins_dict.items():\n",
    "    bin_labels = create_bin_labels(bins)\n",
    "    transformed_data[column] = pd.cut(data[column], bins=bins, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "# Add remaining columns without binning\n",
    "for column in data.columns:\n",
    "    if column not in bins_dict:\n",
    "        transformed_data[column] = data[column]\n",
    "\n",
    "# Save the transformed dataset to a new CSV file\n",
    "output_file_path = '/Users/x/Downloads/transformed_NPHA_doctor_visits.csv'\n",
    "transformed_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "output_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/x/Downloads/transformed_wdbc1.csv'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/x/Downloads/wdbc (1) (1).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Remove the first column (ID column)\n",
    "data = data.drop(data.columns[0], axis=1)\n",
    "\n",
    "# Correctly define binning based on actual column names\n",
    "bins_dict = {\n",
    "    '17.99': [-np.inf, 10, 20, np.inf],   \n",
    "    '10.38': [-np.inf, 5, 15, np.inf],  \n",
    "    '122.8': [-np.inf, 50, 150, np.inf],  \n",
    "    '1001': [-np.inf, 500, 1500, np.inf]  \n",
    "}\n",
    "\n",
    "# Function to determine bin labels\n",
    "def create_bin_labels(bins):\n",
    "    bin_labels = []\n",
    "    for i in range(len(bins) - 1):\n",
    "        if bins[i] == -np.inf:\n",
    "            label = f\"less_than_{bins[i + 1]}\"\n",
    "        elif bins[i + 1] == np.inf:\n",
    "            label = f\"{bins[i]}_or_more\"\n",
    "        else:\n",
    "            label = f\"{bins[i]}_to_{bins[i + 1]}\"\n",
    "        bin_labels.append(label)\n",
    "    return bin_labels\n",
    "\n",
    "# Apply binning\n",
    "transformed_data = data.copy()\n",
    "\n",
    "for column, bins in bins_dict.items():\n",
    "    bin_labels = create_bin_labels(bins)\n",
    "    transformed_data[column] = pd.cut(data[column].astype(float), bins=bins, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "# Save the transformed dataset to a new CSV file\n",
    "output_file_path = '/Users/x/Downloads/transformed_wdbc1.csv'\n",
    "transformed_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "output_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/x/Downloads/transformed_cell_samples1.csv'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/x/Downloads/cell_samples.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Remove the ID column\n",
    "\n",
    "# Define the binning ranges and labels for the columns based on dataset statistics\n",
    "bins_dict = {\n",
    "    'UnifSize': [-np.inf, 1.5, 4.5, np.inf],\n",
    "    'MargAdh': [-np.inf, 1.5, 3.5, np.inf],\n",
    "    'Clump': [-np.inf, 4.5, 6.5, np.inf],\n",
    "    'BlandChrom': [-np.inf, 2.5, 3.5, np.inf],\n",
    "    'UnifShape': [-np.inf, 1.5, 4.5, np.inf],\n",
    "    'NormNucl': [-np.inf, 2.5, 9.5, np.inf],\n",
    "    'Mit': [-np.inf, 1.5, np.inf],\n",
    "    'BareNuc': [-np.inf, 1.5, 3.765, 5.5, np.inf],\n",
    "    'SingEpiSize': [-np.inf, 2.5, 3.5, np.inf]\n",
    "}\n",
    "\n",
    "# Function to determine bin labels\n",
    "def create_bin_labels(bins):\n",
    "    bin_labels = []\n",
    "    for i in range(len(bins) - 1):\n",
    "        if bins[i] == -np.inf:\n",
    "            label = f\"-inf_to_{bins[i + 1]}\"\n",
    "        elif bins[i + 1] == np.inf:\n",
    "            label = f\"{bins[i]}_to_inf\"\n",
    "        else:\n",
    "            label = f\"{bins[i]}_to_{bins[i + 1]}\"\n",
    "        bin_labels.append(label)\n",
    "    return bin_labels\n",
    "\n",
    "# Apply binning\n",
    "transformed_data = pd.DataFrame()\n",
    "\n",
    "for column, bins in bins_dict.items():\n",
    "    bin_labels = create_bin_labels(bins)\n",
    "    transformed_data[column] = pd.cut(data[column].astype(float), bins=bins, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "# Rename columns to the desired format\n",
    "transformed_data.columns = [\n",
    "    'Cell_Size_Uniformity', 'Marginal_Adhesion', 'Clump_Thickness', \n",
    "    'Bland_Chromatin', 'Cell_Shape_Uniformity', 'Normal_Nucleoli', \n",
    "    'Mitoses', 'Bare_Nuclei', 'Single_Epi_Cell_Size'\n",
    "]\n",
    "\n",
    "# Add the 'Class' column without transformation\n",
    "transformed_data['Class'] = data['Class'].map({2: 'benign', 4: 'malignant'})\n",
    "\n",
    "# Save the transformed dataset to a new CSV file\n",
    "output_file_path = '/Users/x/Downloads/transformed_cell_samples1.csv'\n",
    "transformed_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "output_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/x/Downloads/transformed_sonar.csv'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/x/Downloads/sonar.all-data'\n",
    "data = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# Define the binning ranges and labels for the columns based on dataset statistics\n",
    "bin_ranges = [-np.inf, 0.25, 0.5, 0.75, np.inf]\n",
    "\n",
    "# Function to determine bin labels\n",
    "def create_bin_labels(bins):\n",
    "    bin_labels = []\n",
    "    for i in range(len(bins) - 1):\n",
    "        if bins[i] == -np.inf:\n",
    "            label = f\"-inf_to_{bins[i + 1]}\"\n",
    "        elif bins[i + 1] == np.inf:\n",
    "            label = f\"{bins[i]}_to_inf\"\n",
    "        else:\n",
    "            label = f\"{bins[i]}_to_{bins[i + 1]}\"\n",
    "        bin_labels.append(label)\n",
    "    return bin_labels\n",
    "\n",
    "# Generate bin labels\n",
    "bin_labels = create_bin_labels(bin_ranges)\n",
    "\n",
    "# Apply binning\n",
    "transformed_data = pd.DataFrame()\n",
    "\n",
    "for column in data.columns[:-1]:\n",
    "    transformed_data[column] = pd.cut(data[column], bins=bin_ranges, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "# Add the 'Class' column without transformation\n",
    "transformed_data['Class'] = data[data.columns[-1]]\n",
    "\n",
    "# Save the transformed dataset to a new CSV file\n",
    "output_file_path = '/Users/x/Downloads/transformed_sonar.csv'\n",
    "transformed_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "output_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  buying  maint doors persons lug_boot safety  class\n",
      "0  vhigh  vhigh     2       2    small    low  unacc\n",
      "1  vhigh  vhigh     2       2    small    med  unacc\n",
      "2  vhigh  vhigh     2       2    small   high  unacc\n",
      "3  vhigh  vhigh     2       2      med    low  unacc\n",
      "4  vhigh  vhigh     2       2      med    med  unacc\n",
      "Converted dataset saved to /Users/x/Downloads/car_car7.csv\n"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/x/Downloads/car - car.xlsx (6).csv'\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(data.head())\n",
    "\n",
    "# Mapping of categorical values to numerical values\n",
    "mappings = {\n",
    "    'buying': {'vhigh': 4, 'high': 3, 'med': 2, 'low': 1},\n",
    "    'maint': {'vhigh': 4, 'high': 3, 'med': 2, 'low': 1},\n",
    "    'doors': {'5more': 5, '4': 4, '3': 3, '2': 2},\n",
    "    'persons': {'more': 5, '4': 4, '2': 2},\n",
    "    'lug_boot': {'small': 1, 'med': 2, 'big': 3},\n",
    "    'safety': {'low': 1, 'med': 2, 'high': 3},\n",
    "    'class': {'unacc': 0, 'acc': 1, 'good': 2, 'vgood': 3}\n",
    "}\n",
    "\n",
    "# Apply the mappings to convert categorical values to numerical values\n",
    "for column, mapping in mappings.items():\n",
    "    data[column] = data[column].map(mapping)\n",
    "\n",
    "# Save the modified dataset to a new CSV file\n",
    "output_path = '/Users/x/Downloads/car_car7.csv'\n",
    "data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Converted dataset saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/x/Downloads/glass_ruleopt.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data similar to the glass dataset\n",
    "data = pd.read_csv('/Users/x/Downloads/glass1.csv')\n",
    "\n",
    "\n",
    "# Convert the target variable to different values (e.g., 0, 1, 2)\n",
    "data['Type'] = data['Type'].map({1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5})\n",
    "\n",
    "output_path = '/Users/x/Downloads/glass_ruleopt.csv'\n",
    "data.to_csv(output_path, index=False)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/x/Downloads/dry_b_ro.csv')\n",
    "\n",
    "\n",
    "# Map the target variable to integers\n",
    "class_mapping = {\n",
    "    \"SEKER\": 0,\n",
    "    \"BARBUNYA\": 1,\n",
    "    \"BOMBAY\": 2,\n",
    "    \"CALI\": 3,\n",
    "    \"DERMASON\": 4,\n",
    "    \"HOROZ\": 5,\n",
    "    \"SIRA\": 6\n",
    "}\n",
    "\n",
    "df['Class'] = df['Class'].map(class_mapping)\n",
    "\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "output_csv_path = '/Users/x/Downloads/dry_beans_ro_mapped_2.csv'\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
